{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Unigram probabilities in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"After winning re-election by defeating Republican opponent Mitt Romney, Obama was sworn in for a second term in 2013. During this term, he promoted inclusion for LGBT Americans. His administration filed briefs that urged the Supreme Court to strike down same-sex marriage bans as unconstitutional (United States v. Windsor and Obergefell v. Hodges); same-sex marriage was legalized nationwide in 2015 after the Court ruled so in Obergefell. He advocated for gun control in response to the Sandy Hook Elementary School shooting, indicating support for a ban on assault weapons, and issued wide-ranging executive actions concerning global warming and immigration. In foreign policy, he ordered military intervention in Iraq in response to gains made by ISIL after the 2011 withdrawal from Iraq, continued the process of ending U.S. combat operations in Afghanistan in 2016, promoted discussions that led to the 2015 Paris Agreement on global climate change, initiated sanctions against Russia following the invasion in Ukraine and again after Russian interference in the 2016 United States elections, brokered a nuclear deal with Iran, and normalized U.S. relations with Cuba. Obama nominated three justices to the Supreme Court: Sonia Sotomayor and Elena Kagan were confirmed as justices, while Merrick Garland faced unprecedented partisan obstruction and was ultimately not confirmed. During his term in office, America's soft power and reputation abroad significantly improved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.tokens.token.Token' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bfec9b4ed9cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bfec9b4ed9cf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'spacy.tokens.token.Token' object is not iterable"
     ]
    }
   ],
   "source": [
    "docs = nlp(text)\n",
    "probs = [(sum(tok.prob for tok in doc), doc) for doc in docs]\n",
    "prob, doc = max(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/suguthansekar/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source - http://www.katrinerk.com/courses/python-worksheets/language-models-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_brown_1gram = nltk.FreqDist(brown.words())\n",
    "\n",
    "len_brown = len(brown.words())\n",
    "\n",
    "\n",
    "def unigram_prob(word):\n",
    "    return freq_brown_1gram[ word] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62713"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '“If diseases carried by the new influx of people from the Steppe played a part in changing the demography of Europe, it wouldn’t be the last time this happened, of course. The diseases carried by the Europeans into the Americas played a significant role in decimating the original population of that continent. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "tokens = [(token.text,token.prob, unigram_prob(token.text)) for token in doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('“', -20.0, 0)\n",
      "1 ('If', -20.0, 732)\n",
      "2 ('diseases', -20.0, 16)\n",
      "3 ('carried', -20.0, 124)\n",
      "4 ('by', -20.0, 5103)\n",
      "5 ('the', -20.0, 62713)\n",
      "6 ('new', -20.0, 1060)\n",
      "7 ('influx', -20.0, 4)\n",
      "8 ('of', -20.0, 36080)\n",
      "9 ('people', -20.0, 811)\n",
      "10 ('from', -20.0, 4207)\n",
      "11 ('the', -20.0, 62713)\n",
      "12 ('Steppe', -20.0, 0)\n",
      "13 ('played', -20.0, 103)\n",
      "14 ('a', -20.0, 21881)\n",
      "15 ('part', -20.0, 465)\n",
      "16 ('in', -20.0, 19536)\n",
      "17 ('changing', -20.0, 40)\n",
      "18 ('the', -20.0, 62713)\n",
      "19 ('demography', -20.0, 3)\n",
      "20 ('of', -20.0, 36080)\n",
      "21 ('Europe', -20.0, 118)\n",
      "22 (',', -20.0, 58334)\n",
      "23 ('it', -20.0, 6723)\n",
      "24 ('would', -20.0, 2677)\n",
      "25 ('n’t', -20.0, 0)\n",
      "26 ('be', -20.0, 6344)\n",
      "27 ('the', -20.0, 62713)\n",
      "28 ('last', -20.0, 636)\n",
      "29 ('time', -20.0, 1556)\n",
      "30 ('this', -20.0, 3966)\n",
      "31 ('happened', -20.0, 146)\n",
      "32 (',', -20.0, 58334)\n",
      "33 ('of', -20.0, 36080)\n",
      "34 ('course', -20.0, 464)\n",
      "35 ('.', -20.0, 49346)\n",
      "36 ('The', -20.0, 7258)\n",
      "37 ('diseases', -20.0, 16)\n",
      "38 ('carried', -20.0, 124)\n",
      "39 ('by', -20.0, 5103)\n",
      "40 ('the', -20.0, 62713)\n",
      "41 ('Europeans', -20.0, 5)\n",
      "42 ('into', -20.0, 1782)\n",
      "43 ('the', -20.0, 62713)\n",
      "44 ('Americas', -20.0, 1)\n",
      "45 ('played', -20.0, 103)\n",
      "46 ('a', -20.0, 21881)\n",
      "47 ('significant', -20.0, 84)\n",
      "48 ('role', -20.0, 104)\n",
      "49 ('in', -20.0, 19536)\n",
      "50 ('decimating', -20.0, 0)\n",
      "51 ('the', -20.0, 62713)\n",
      "52 ('original', -20.0, 102)\n",
      "53 ('population', -20.0, 136)\n",
      "54 ('of', -20.0, 36080)\n",
      "55 ('that', -20.0, 10237)\n",
      "56 ('continent', -20.0, 11)\n",
      "57 ('.', -20.0, 49346)\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(tokens):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If\n",
      "diseases\n",
      "carried\n",
      "people\n",
      "played\n",
      "part\n",
      "changing\n",
      "Europe\n",
      "last\n",
      "happened\n",
      "course\n",
      "diseases\n",
      "carried\n",
      "played\n",
      "significant\n",
      "role\n",
      "original\n",
      "population\n",
      "continent\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(tokens):\n",
    "    if j[2] > 10 and j[2] <1000:\n",
    "        print(j[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob('Hawaii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Length of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ('diseases', -20.0, 16)\n",
      "3 ('carried', -20.0, 124)\n",
      "7 ('influx', -20.0, 4)\n",
      "9 ('people', -20.0, 811)\n",
      "12 ('Steppe', -20.0, 0)\n",
      "13 ('played', -20.0, 103)\n",
      "17 ('changing', -20.0, 40)\n",
      "19 ('demography', -20.0, 3)\n",
      "21 ('Europe', -20.0, 118)\n",
      "24 ('would', -20.0, 2677)\n",
      "31 ('happened', -20.0, 146)\n",
      "34 ('course', -20.0, 464)\n",
      "37 ('diseases', -20.0, 16)\n",
      "38 ('carried', -20.0, 124)\n",
      "41 ('Europeans', -20.0, 5)\n",
      "44 ('Americas', -20.0, 1)\n",
      "45 ('played', -20.0, 103)\n",
      "47 ('significant', -20.0, 84)\n",
      "50 ('decimating', -20.0, 0)\n",
      "52 ('original', -20.0, 102)\n",
      "53 ('population', -20.0, 136)\n",
      "56 ('continent', -20.0, 11)\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(tokens):\n",
    "    if len(j[0]) > 4:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('“', -20.0, 0),\n",
       " ('Steppe', -20.0, 0),\n",
       " ('n’t', -20.0, 0),\n",
       " ('decimating', -20.0, 0),\n",
       " ('Americas', -20.0, 1),\n",
       " ('demography', -20.0, 3),\n",
       " ('influx', -20.0, 4),\n",
       " ('Europeans', -20.0, 5),\n",
       " ('continent', -20.0, 11),\n",
       " ('diseases', -20.0, 16),\n",
       " ('diseases', -20.0, 16),\n",
       " ('changing', -20.0, 40),\n",
       " ('significant', -20.0, 84),\n",
       " ('original', -20.0, 102),\n",
       " ('played', -20.0, 103),\n",
       " ('played', -20.0, 103),\n",
       " ('role', -20.0, 104),\n",
       " ('Europe', -20.0, 118),\n",
       " ('carried', -20.0, 124),\n",
       " ('carried', -20.0, 124),\n",
       " ('population', -20.0, 136),\n",
       " ('happened', -20.0, 146),\n",
       " ('course', -20.0, 464),\n",
       " ('part', -20.0, 465),\n",
       " ('last', -20.0, 636),\n",
       " ('If', -20.0, 732),\n",
       " ('people', -20.0, 811),\n",
       " ('new', -20.0, 1060),\n",
       " ('time', -20.0, 1556),\n",
       " ('into', -20.0, 1782),\n",
       " ('would', -20.0, 2677),\n",
       " ('this', -20.0, 3966),\n",
       " ('from', -20.0, 4207),\n",
       " ('by', -20.0, 5103),\n",
       " ('by', -20.0, 5103),\n",
       " ('be', -20.0, 6344),\n",
       " ('it', -20.0, 6723),\n",
       " ('The', -20.0, 7258),\n",
       " ('that', -20.0, 10237),\n",
       " ('in', -20.0, 19536),\n",
       " ('in', -20.0, 19536),\n",
       " ('a', -20.0, 21881),\n",
       " ('a', -20.0, 21881),\n",
       " ('of', -20.0, 36080),\n",
       " ('of', -20.0, 36080),\n",
       " ('of', -20.0, 36080),\n",
       " ('of', -20.0, 36080),\n",
       " ('.', -20.0, 49346),\n",
       " ('.', -20.0, 49346),\n",
       " (',', -20.0, 58334),\n",
       " (',', -20.0, 58334),\n",
       " ('the', -20.0, 62713),\n",
       " ('the', -20.0, 62713),\n",
       " ('the', -20.0, 62713),\n",
       " ('the', -20.0, 62713),\n",
       " ('the', -20.0, 62713),\n",
       " ('the', -20.0, 62713),\n",
       " ('the', -20.0, 62713)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getKey(item):\n",
    "    return item[2]\n",
    "l = [[2, 3], [6, 7], [3, 34], [24, 64], [1, 43]]\n",
    "sorted(tokens, key=getKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
